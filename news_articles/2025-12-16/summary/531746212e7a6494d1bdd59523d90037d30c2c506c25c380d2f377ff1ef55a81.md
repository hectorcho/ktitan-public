## AI가 수능 풀어보니… 제미나이는 92점, 한국 모델은 20점대
## 주요 내용:
*   서강대 김종락 교수 연구팀이 국내외 대형 언어 모델(LLM) 10개를 대상으로 수능 수학 및 논술 문제 풀이 능력을 실험했다.
*   실험 결과, 구글 제미나이 3 프로는 92점, 앤트로픽 클로드 오퍼스 4.5는 84점을 받는 등 해외 모델은 76~92점의 높은 점수를 기록했다.
*   반면, 한국 모델 중에서는 업스테이지의 '솔라 프로-2'가 58점을 받았고, 나머지 모델들은 20점대에 머물렀으며, 엔씨소프트의 '라마 바르코 8B 인스트럭트'는 2점을 받았다.
*   연구팀은 한국 모델이 단순 추론 기능으로는 문제를 잘 해결하지 못해 인센티브를 제공했음에도 해외 모델과의 성능 격차가 컸다고 설명했다.
*   테크 업계에서는 이 실험 결과가 '비효율적인 소버린 AI 구축'의 사례로 지적되며, 무작정 국가대표 AI를 개발하기보다 다양한 AI 활용 전략을 고심해야 한다는 의견이 나왔다.

## 요약
서강대 김종락 교수 연구팀이 국내외 10개 대형 언어 모델(LLM)의 수능 수학 및 논술 문제 풀이 능력을 비교하는 실험을 진행했다. 이 실험에는 국내 '국가대표 AI' 개발에 도전하는 5개 팀의 모델과 오픈AI, 구글 등 해외 5개 모델이 참여했다. 총 50문제(수능 수학 20문제, 논술 30문제)를 풀게 한 결과, 해외 모델들이 압도적인 성능을 보였다.

구글 제미나이 3 프로는 92점, 앤트로픽의 클로드 오퍼스 4.5는 84점을 기록하는 등 해외 모델들은 76점에서 92점 사이의 높은 점수를 받았다. 이에 비해 한국 모델들은 업스테이지의 '솔라 프로-2'가 58점을 기록한 것을 제외하고는 대부분 20점대에 머물렀으며, 엔씨소프트의 '라마 바르코 8B 인스트럭트'는 단 2점을 받는 등 해외 모델과의 성능 격차가 매우 크게 나타났다.

연구팀은 한국 모델들이 단순 추론 기능만으로는 문제를 해결하기 어려워 추가적인 인센티브를 제공했음에도 불구하고 이러한 격차가 발생했다고 설명했다. 테크 업계에서는 이번 실험 결과가 '비효율적인 소버린 AI 구축'의 단적인 예시로 지적되며, 국가 안보 측면에서 자체 AI 개발의 중요성이 인정되더라도, 해외 모델 대비 성능이 현저히 떨어지는 경우 무작정 개발하기보다는 다양한 AI 활용 전략을 모색해야 한다는 비판적인 시각이 제기되고 있다.